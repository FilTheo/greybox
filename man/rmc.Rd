% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rmc.R
\name{rmc}
\alias{rmc}
\title{RMC test}
\usage{
rmc(data, value = c("normal", "absolute", "squared"), level = 0.95,
  sort = TRUE, style = c("mcb", "lines"), select = NULL, plot = TRUE,
  ...)
}
\arguments{
\item{data}{Matrix or data frame with observations in rows and variables in
columns.}

\item{value}{Type of the provided value. If this is a clear forecast error,
then \code{"normal"} is appropriate, leading to a simple Gausian linear
regression. \code{"absolute"} would lead to truncated regression (if the
package "truncreg" is installed. Otherwise this will be a linear regression).
Finally, \code{"squared"} would lead to the glm with Gamma distribution.}

\item{level}{The width of the confidence interval. Default is 0.95.}

\item{sort}{If \code{TRUE} function sorts the final values of mean ranks.
If plots are requested via \code{type} parameter, then this is forced to
\code{TRUE}.}

\item{style}{What style of plot to use after the calculations. This can be
either "MCB" style or "Vertical lines" one.}

\item{select}{What column of data to highlight on the plot. If NULL, then
the method with the lowest value is selected.}

\item{plot}{If \code{TRUE} then the graph is produced after the calculations.
You can also use plot method on the produced object in order to get the same
effect.}

\item{...}{Other parameters passed to plot function}
}
\value{
Function returns the following variables:
\itemize{
\item{mean}{Mean rank of each method.}
\item{interval}{rmc intervals for each method.}
\item{p.value}{Friedman test p-value.}
\item{level}{Singificance level.}
\item{model}{lm model produced for the calculation of the intervals.}
\item{style}{Style of the plot to produce.}
\item{select}{The selected variable to highlight.}
}
}
\description{
RMC stands for "Regression for Methods Comparison". This is a parametric
test for the comparison of medians of several distributions
This test is a parametric counterpart of nemenyi / MCB test and uses
asymptotic properties of regression models.
}
\details{
The advisable error measures to use for data are RelMAE and RelMSE, which are
unbiased and have good properties. Don't forget to take logarythms of measures
first. See examples for more details on how to use them.

The test is equivalent to nemenyi test, when applied to the ranks of the error
measures on large samples.
}
\examples{
N <- 50
M <- 4
ourData <- matrix(rnorm(N*M,mean=0,sd=1), N, M)
ourData[,2] <- ourData[,2]+1
ourData[,3] <- ourData[,3]+0.7
ourData[,4] <- ourData[,4]+0.5
colnames(ourData) <- c("Method A","Method B","Method C - long name","Method D")
rmc(ourData, value="n", level=0.95)
par(mar=c(2,0,2,0),cex=1.5)
rmc(ourData, level=0.95)

# In case of AE-based measures, value="a" should be selected
rmc(abs(ourData), value="a", level=0.95)

# In case of SE-based measures, value="s" should be selected
rmc(ourData^2, value="s", level=0.95)

# APE-based measures should not be used in general...

# If RelMAE or RelMSE is used for measuring data, then it makes sense to use
# value="n" and provide logarithms of the RelMAE, which will have asymptotic
# normal distribution
ourData <- abs(ourData)
ourData <- ourData / ourData[,1]
rmc(ourData, value="n", level=0.95)

# The following example should give similar results to nemenyi test on
# large samples:
rmc(t(apply(ourData,1,rank)), value="n", level=0.95)

}
\references{
\itemize{
\item ???
}
}
\author{
Ivan Svetunkov, \email{ivan@svetunkov.ru}
}
\keyword{htest}
