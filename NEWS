greybox v0.3.2 (Release data: 2018-10-25)
==============

Changes:
* Updates in the vignette of alm.
* Although the square link is tricky in case of Chi Squared distribution, it is the correct thing to do. The alm() function now checks if the generated mu_t is positive, and if not, it returns a big number, forcing the solver to stick with the positive solution.
* If inverting Hessian fails, return very big values (meaning high uncertainty).
* predict.alm() now saves the original level of probability.
* New initialisation for plogis, pnorm, dpois and dnbinom in alm().
* dpois, plogis, pnorm and dnbinom now use maxeval=500. All the others have 100. This should improve the estimates of parameters in difficult cases.
* We now return only that data, that was used in the model construction in alm().
* lmCombine and lmDynamic now should work with the distributions of alm(). The only two that are not 100% correct are dchisq and dfnorm - the fitted values of those are incorrect.
* removed getResponse.alm. Now getResponse.greybox does what is necessary.
* Residuals of dnbinom and dpois are now calculated as y - fitted.
* predict with distriubion="dnbinom" in cases, when scale is not available, is now calculated based on the definition of scale via variance and mean.
* pointLik.ets() is now calculated differently, so that sum(pointLik) is close to the logLik produced by ets() function. The problem with logLik of ets() is that it is not calculated correctly, chopping off some parts of normal distribution. Total disaster!
* New set of distribution functions - for Asymmetric Laplace Distribution (ALD).
* alm() now estimates models with Asymmetric Laplace Distribution with predefined alpha parameter. This is equivalent to the quantile regression with alpha quantile, but is done from the likelihood point of view. It also allows estimating alpha in sample.
* The correct prediction and confidence intervals for the alm() with ALD.
* predict function now also works, when newdata is not provided (although why would you want to do that?).

Bugfixes:
* predict.alm() sometimes produced NAs in the lower bound.
* When having varying probability, plot.predict sometimes struggled to use the correct value.
* plot.predict.greybox() now passes values from ellipsis to graphmaker.
* The intervals for dnorm are now corrected for the cases of occurrence model.
* plot.predict works differently when there are Inf values in the bounds.
* predict() did not work correctly for simple linear regression.
* alm() returned a vector in data for cases of the model with intercept only.
* predict.alm() with distribution=c(dlaplace, ds, dfnorm) did not work in some cases of fixed level of probability.
* predict.alm() now writes lower and upper values in the existing elements of the list instead of creating the new ones.
* predict.alm() did not produce prediction intervals for "dnorm".
* plot.greybox() now checks whether there is a need to transform the data to the binary variable or not.


greybox v0.3.1 (Release data: 2018-09-07)
==============

Changes:
* Corrected some typos in README.md and added description of several functions.
* predict() and forecast() functions now produce confidence and prediction intervals for the provided holdout sample data. forecast() is just a wrapper around predict().
* Normal and log-normal distributions are now available in alm().
* rmc() now uses alm().
* stepwise(), lmCombine() and lmDynamic() can now also be constructed with distributions from alm(). They use lm() in case of "dnorm" and alm() otherwise.
* alm() now does not return vcov if you didn't ask for it (should increase speed of computation for large datasets).
* alm() can be constructed with the provided vector of parameters (needed for vcov method).
* We now use well-known analytical solutions for the cases of distribution="dnorm" of alm() and other functions.
* Code of lmCombine and lmDynamic is slightly simplified.
* We now use Choleski decomposition for the calculation of the inverse of matrices in alm.
* distribution="dlogis" is now available for alm().
* alm() now also supports logit and probit models, which are called using distribution="plogis" and distribution="pnorm" respectively (reference to the names of respective CDFs in R).
* alm() now has occurrence parameter, which allows dealing with zeroes in the data. In this case, a mixture distribution can be used.
* alm() with dlnorm now also returns analytical covariance matrix instead of hessian based one.
* stepwise(), lmCombine() and lmDynamic() now rely on .lm.fit() function, when distribution="dnorm", so the speed of calculation should be substantially higher.
* New functions for class checks: is.greybox(), is.alm(), is.greyboxC(), is.greyboxD(), is.rmc() and is.rollingOrigin().
* stepwise() now calculates only the necessary correlations. This allows further inceasing the speed of computation.
* alm() uses its own mean function, so this should also increas its speed.
* Correct prediction intervals for the model with the occurrence part and a new parameter in prediction function - side - which allows producing one-sided PIs.
* stepwise() should now work better with big data.
* Futher optimisation of stepwise in order to decrease the used memory.
* alm() and all the other functions now return "data" instead of "model" and don't produce terms and qr. This should save some space.
* vcov.alm() now uses call in order to reestimate the model.
* rmc() now returns groups of methods. This can be used for analytical purposes.
* alm() now uses a more refined parameters for vcov calculation for "dchisq" and returns a slightly different call with vcov.
* pointLik.alm() method for alm class.
* alm() now extracts meaningful residuals depending on the distribution used. e.g. dnorm -> y - mu, dlnorm -> log(y) - mu
* stepwise() now allows defining occurrence model. So now you can do something like: stepwise(ourData, distribution="dlnorm", occurrence=stepwise(ourData, distribution="plogis"))
* predict function now returns probabilities for the lower and upper intervals. So if you had side="upper", then the lower will be "0", and the upper will be the specified level.
* dpois and dnbinom distributions in alm. alm() allows producing prediction intervals for both of them. But covariance matrix of parameters for dnbinom might be hard to calculate...
* The dispersion parameter of dnbinom in alm() is now estimated separately, which now solves a lot of problems.
* Renamed parameter A into B for alm(). Very serious thing!
* distribution="dchisq" in alm() now estimates the non-central Chi Squared distribution. The returned scale corresponds to the estimated number of degrees of freedom, while mu is the exponent of the expectation.
* rmc() now colours the lines depending on the number of groups. If there's only one, then there's one group and the differences are not significant.
* Started a new vignette for the alm() function.
* graphmaker() is now moved from smooth to greybox.

Bugfixes:
* Fixed a bug with the style="line" in rmc(), where the grouping would be wrong in cases, when one method significantly differs from the others.
* logLik previously was not calculated correctly for the mixture models.
* Bugfix in hessian calculation, when Choleski decomposition works...
* Bugfix in pointLik for the models with occurrence.
* predict() function failed with newdata with one observation.
* Initials of both Poisson and NegBin in case of non-zero data are now taken with logs. This leads to more robust starting points.


greybox v0.3.0 (Release data: 2018-08-05)
==============

Changes:
* New cool function - lmDynamic() - that constructs a dynamic linear regression based on point ICs.
* New set of functions for Folded normal distribution.
* New function - alm - Advanced Linear Model.
* Folded normal distribution for rmc() with value="a".
* Proper model for chi-squared distribution in alm and rmc.
* Renamed distributions in the alm function.

Bugfixes:
* determination() function did not work in cases of 2 variables.
* vcov() and confint() were misbehaving when nVars==1.

greybox v0.2.3 (Release data: 2018-08-02)
==============

Changes:
* determination() now automatically drops variables with no variability.
* New function - nemenyi() - imported from TStools with minor bugfixes and corrections.
* It appears that Nikos is against the move of nemenyi() function from TStools to greybox. This was a misunderstanding between the two of us. So no nemenyi() function here, nothing to see here, move along!
* New function for multiple comparison of methods based on regression analysis - rmc(). This is a parametric analogue of nemenyi test. The function works with errors, their absolute and squared values and relies on lm / glm.
* New methods imported from smooth: errorType, pointLik and pAIC.

Bugfixes:
* plots of ro() were misaligned in case of co=FALSE
* ro() now also returns the correct actual values (previously they could be cut off when ci=FALSE).


greybox v0.2.2 (Release data: 2018-05-25)
==============

Changes:
* New description of the package and badges in README.md
* New function - determination() - returns R-squares for the provided data. This can be useful when you need to analyse the multicollinearity effect.
* nParam method for logLik class.
* BICc - new method for the classes, implementing, guess what?
* Updated description of the package in the help file.
* ro() now returns a class and has print and plot methods associated with it.
* ro() is much more flexible now, returning whatever you want in an adequate format.
* New methods for the greybox functions: confint, vcov.
* Renamed "combiner" into "lmCombine", because it makes more sense. We will use "combine" name for a more general function that would combine forecasts from arbitrary provided models (e.g. smooth, forecast and lm classes).

Bugfixes:
* sigma() method returned the wrong standard error in cases of combined models.


greybox v0.2.1 (Release data: 2018-05-01)
==============

Changes:
* New description of the package and badges in README.md


greybox v0.2.1 (Release data: 2018-05-01)
==============

Changes:
* print.summary now specifies digits. Summary does not round up anything. This corresponds to the normal behaviour of these methods.
* Implemented Laplace distribution, which is useful when models are estimated using MAE.
* Sped up qs() and qlaplace() functions using the inverse cumulative functions.
* New function - ro() - Rolling origin.

Bugfixes:
* qs() returned weird values when several 0 and 1 were specified as probabilities.

greybox v0.2.0 (Release data: 2018-03-10)
==============

Changes:
* combiner now uses a more clever mechanism in case of bruteForce==FALSE.
* combiner now also checks if the provided data has ncol>nrow and sets bruteForce if it has.
* Use Kendall Tau as default in cor() for stepwise.
* Don't use Kendall Tau as default everywhere - only for fat regressions.
* New summary and print methods for models from stepwise. No statistical tests printed, only confidence intervals and ICs.
* AICc for smooth functions in case of iSS models should take only the demand sizes into account, not all the parameters.


greybox v0.1.1 (Release data: 2018-03-05)
==============

Changes:
* We now do not depend on smooth. We suggest it. It's smooth that should depend on greybox!
* New function imported from smooth - AICc.
* New functions for the S distribution (the maximisation of likelihood of which corresponds to the minimum of HAM): ds, ps, qs, rs.
* stepwise now returns the object of two classes: greybox and lm.
* combiner now returns three classes: greybox, lm and greyboxC.
* nParam is moved to greybox from smooth.

Bugfixes:
* If smooth is not installed, plot forecasts using simpler function.
* The forecasts are now produced for the combined models in cases of fat regressions.


greybox v0.1.0 (Release data: 2018-03-03)
==============

* Initial release. stepwise() and xregExpander() are imported here from smooth package.
* combiner() function that combines lm() models. This thing is in the development right now.
* combiner() has a meaningful summary() now. Working to make it more accesible to lm functions.
* summary() for combiner now returns the list of values.
* stepwise() should now perform slightly better.
* combiner() can now be smart and use stepwise for the models pool creation.
* combined lm model can now be used together with predict() and forecast() functions.
* plot() and forecast() methods for the combined functions.
